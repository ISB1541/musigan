{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product \"MUSIGAN\"\n",
    "### Creative beats & melody recommendation tool for music creators\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Music creators for professionals or amatuers (TBD) select \"Influencers\" and \"Derivative Measurement\".  Musigan recommends a beat or melody utilizing a GAN (Generative Adversarial Network) algorithm to generative recommend audio samples.  Initially, the audio sound bites will be 10 seconds and be trained by available data on SoundCloud. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the process of finding the \"right\" beat or melody? \n",
    "  * Is it iterative?  \n",
    "  * Do you start with a familiar spot? \n",
    "  * How long does it normally take to find the right sound?\n",
    "* What genres do you normally play? (Gather general background of music creating history)\n",
    "* (TBD)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Requirements (iPhone App)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select influencers\n",
    "* Select amount of derivative scale from influencer\n",
    "* Algo returns list of recommended beats\n",
    "* Users can combine variations of beats and save new song  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Musigan GANs Pseudocode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user_inputs = influencers, derivative scale\n",
    "training_data = SoundCloud database \n",
    "\n",
    "####-----------Potential Derivative Scale Generation------------####\n",
    "\n",
    "#-# derivative scale is a user adjusted scale from Influencer match and generic genre\n",
    "\n",
    "target_beat(influencer, deriv_scale):\n",
    "    \n",
    "    # influencer_array is the pre-defined beat of the most well-known beat from influencer. (can expand in v2)  \n",
    "    \n",
    "    influencer_array = find_influencer_array(influencer, SoundCloud) \n",
    "    \n",
    "    # target_beat is the scale of derivative beat from the original influencer. \n",
    "    # deriv_scale range [1,100], deriv_scale == 1 returns influencer\n",
    "    \n",
    "    target_beat = influencer_array * deriv_scale\n",
    "    \n",
    "    return target_beat\n",
    "\n",
    "\n",
    "####------------------------GANs Pseudocode---------------------####\n",
    "\n",
    "while equilibrium_not_reached:\n",
    "    \n",
    "    # train the discriminator to classify a batch of audio files from our\n",
    "    # dataset as real and a batch of audio generated by our current generator as fake\n",
    " \n",
    "    discriminator.train_on_batch(audio_batch=real_audio_batch, labels=real)\n",
    "    \n",
    "    discriminator.train_on_batch(audio_batch=generated_audio_batch, labels=fake)\n",
    "\n",
    "    # train the generator to trick the discriminator into classifying a batch of generated audio files as real.\n",
    "    # The key here is that the discriminator is frozen (not trainable) in this step, \n",
    "    # but it's loss functions gradients are back-propagated through the combined network to the generator\n",
    "    # the generator updates its weights in the most ideal way possible based on these gradients\n",
    "    \n",
    "    combined.train_on_batch(input=batch_of_noise, labels=real)\n",
    "    \n",
    "    # where combined is a model that consists of the generator and\n",
    "    # discriminator joined together such that: input => generator =>\n",
    "    # generator_output => discriminator => classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: I think it's best to start with training the GANs on artist-tagged audio clips then once successfully implemented, we can explore derivative-scale algos including post artist-tagged GANs adjustments and graphical models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
